{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import model\n",
    "import metrics\n",
    "import config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from dataset import HistoricalImagesDataset\n",
    "import config\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMAGES_PATH = r'..\\data\\patches\\images\\1942'\n",
    "MASK_PATH = r'..\\data\\patches\\masks\\1942'\n",
    "\n",
    "image_paths = glob.glob(IMAGES_PATH +'\\*.tif')\n",
    "mask_paths = glob.glob(MASK_PATH +'\\*.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image patches: 858 \n",
      "Number of mask patches: 858\n",
      "shape image torch.Size([1, 512, 512]) shape mask torch.Size([1, 512, 512])\n",
      "Splitting data into TRAIN, VAL and TEST\n",
      "Training set size:  8\n",
      "Validation set size:  9\n"
     ]
    }
   ],
   "source": [
    "# Dataset Object \n",
    "print('Number of image patches:', len(image_paths),'\\nNumber of mask patches:', len(mask_paths))\n",
    "dataset = HistoricalImagesDataset(image_paths, mask_paths)\n",
    "data = next(iter(dataset))\n",
    "print('shape image', data[0].shape, 'shape mask', data[1].shape)       \n",
    "\n",
    "# Train, Test, Split -- DEVEOLP A SPLITTING STRATEGY BASED ON THE SPATIAL INFORMATION !!!!!!!!!\n",
    "print('Splitting data into TRAIN, VAL and TEST')\n",
    "train_size = int(0.02 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) #-- pytorch alternative to the train_test_split command line from Scikit-Learn\n",
    "\n",
    "train_size = int(0.5 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "print(\"Training set size: \", len(train_dataset))\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size = config.BATCH_SIZE)\n",
    "print(\"Validation set size: \", len(val_dataset))\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size = config.BATCH_SIZE)\n",
    "# print(\"Testing set size: \", len(test_dataset))\n",
    "# test_dataloader = DataLoader(dataset=test_dataset, batch_size = config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = smp.Unet(\n",
    "    encoder_name= config.BACKBONE,  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=config.N_CHANNELS,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes= config.N_CLASSES,    # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optmization, Number of Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our model\n",
    "model = unet_model.to(config.DEVICE)\n",
    "\n",
    "# initialize loss function and optimizer\n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# calculate steps per epoch for training and test set\n",
    "trainSteps = len(train_dataset) // config.BATCH_SIZE\n",
    "valSteps = len(val_dataset) // config.BATCH_SIZE\n",
    "\n",
    "# initialize a dictionary to store TRAINING history (keep track on training)\n",
    "training_history = {\"avg_train_loss\": [], \"train_accuracy\": []}\n",
    "\n",
    "# initialize a dictionary to store VALIDATION history (keep track on VALIDATION)\n",
    "validation_history = {\"avg_val_loss\": [], \"val_accuracy\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): MobileNetV2Encoder(\n",
      "    (features): Sequential(\n",
      "      (0): ConvNormActivation(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (1): ConvNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU6(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ConvNormActivation(\n",
      "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(1376, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(288, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "print(unet_model)\n",
    "fc = nn.Sequential(nn.Linear(in_features=32, out_features=1, bias=True), nn.Sigmoid()) # 512 neurons, 2 classes\n",
    "model.fc = fc\n",
    "\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network...ðŸ¤—\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0301)\n",
      "tensor(0.1020)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 1/5 [00:17<01:10, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1756)\n",
      "avg train loss 0.013921799138188362\n",
      "val loss tensor(0.1539)\n",
      "[INFO] EPOCH: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0140)\n",
      "tensor(0.0471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:34<00:52, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0794)\n",
      "avg train loss 0.009077801369130611\n",
      "val loss tensor(0.0703)\n",
      "[INFO] EPOCH: 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0067)\n",
      "tensor(0.0219)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:51<00:34, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0368)\n",
      "avg train loss 0.007229072041809559\n",
      "val loss tensor(0.0327)\n",
      "[INFO] EPOCH: 3/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0043)\n",
      "tensor(0.0120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [01:08<00:17, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0201)\n",
      "avg train loss 0.006367039401084185\n",
      "val loss tensor(0.0182)\n",
      "[INFO] EPOCH: 4/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0038)\n",
      "tensor(0.0084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:26<00:00, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0148)\n",
      "avg train loss 0.0059889862313866615\n",
      "val loss tensor(0.0135)\n",
      "[INFO] EPOCH: 5/2\n",
      "{'avg_train_loss': [array(0.90467644, dtype=float32), array(0.4554322, dtype=float32), array(0.18268591, dtype=float32), array(0.06770437, dtype=float32), array(0.02665778, dtype=float32), array(0.0139218, dtype=float32), array(0.0090778, dtype=float32), array(0.00722907, dtype=float32), array(0.00636704, dtype=float32), array(0.00598899, dtype=float32)], 'train_accuracy': []}\n",
      "{'avg_val_loss': [array(3622.6348, dtype=float32), array(53.6239, dtype=float32), array(3.375298, dtype=float32), array(0.8140429, dtype=float32), array(0.3576891, dtype=float32), array(0.15386741, dtype=float32), array(0.07028741, dtype=float32), array(0.03271876, dtype=float32), array(0.01816257, dtype=float32), array(0.01350026, dtype=float32)], 'val_accuracy': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the network \n",
    "print('Training the network...ðŸ¤—')\n",
    "for e in tqdm(range(5)):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each epoch initialize the: \n",
    "    # total training\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "\n",
    "    # number of correctly classified pixels and the total number of pixels\n",
    "    train_correct = 0\n",
    "    total_n_pixels = 0\n",
    "\n",
    "    # loop over the training set\n",
    "    loop = tqdm(train_dataloader, leave=False)\n",
    "    for x, y in loop:\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = model(x)\n",
    "        loss = lossFunc(pred, y)\n",
    "        \n",
    "        opt.zero_grad()  # zero out any previously accumulated gradients\n",
    "        loss.backward() # obtain the gradients with respect to the loss\n",
    "        opt.step() # perform one step of gradient descendent\n",
    "        totalTrainLoss += loss  # add the loss to the total training loss so far\n",
    "        \n",
    "        \n",
    "    # switch off autograd\n",
    "    with torch.no_grad():\n",
    "    # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        for (x_val, y_val) in val_dataloader:\n",
    "            # send the input to the device\n",
    "            (x_val, y_val) = (x_val.to(config.DEVICE), y_val.to(config.DEVICE))\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred_val = model(x_val)\n",
    "            loss = lossFunc(pred_val, y_val)\n",
    "            totalValLoss += loss\n",
    "            print(loss)\n",
    "\n",
    "    # calculate the average training and validation loss PER EPOCH\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps \n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "    \n",
    "    print(f'avg train loss {avgTrainLoss}')\n",
    "    print('val loss', avgValLoss)\n",
    "\n",
    "    ## update training history\n",
    "    training_history[\"avg_train_loss\"].append(avgTrainLoss.cpu().detach().numpy()) # save the avg loss\n",
    "    validation_history[\"avg_val_loss\"].append(avgValLoss.cpu().detach().numpy()) # save the avg loss\n",
    "\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, config.NUM_EPOCHS))\n",
    "\n",
    "print(training_history)\n",
    "print(validation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(3622.6348, dtype=float32),\n",
       " array(53.6239, dtype=float32),\n",
       " array(3.375298, dtype=float32),\n",
       " array(0.8140429, dtype=float32),\n",
       " array(0.3576891, dtype=float32),\n",
       " array(0.15386741, dtype=float32),\n",
       " array(0.07028741, dtype=float32),\n",
       " array(0.03271876, dtype=float32),\n",
       " array(0.01816257, dtype=float32),\n",
       " array(0.01350026, dtype=float32)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_history['avg_val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25081082040>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ0UlEQVR4nO3db4xU973f8fdndzEsYP6ZnQ1ecMAOtnfWVXC8orRWq9s4qWlaBedBJFI1tqpIRBZpkyrVlZ0nzX2AlAc3Sa+r2hJOUuN701gozpVRZLvXdXN7FcnXZJ1wjQETE+OYDRQWsAFjB9jdbx/Mb82wnt2d3Z2dMzPn85JG58xvzpn5zgCfOfzOb85PEYGZmeVDW9YFmJlZ/Tj0zcxyxKFvZpYjDn0zsxxx6JuZ5UhH1gVMZeXKlbF27dqsyzAzayqvvPLK6YjoGt/e8KG/du1aBgYGsi7DzKypSPp9pXZ375iZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWI60b+nsfh9eezroKM7OG0rqh/5u/hN/8VdZVmJk1lNYN/UIRTh3Kugozs4bS2qF/4QS8fzbrSszMGkZrhz74aN/MrMyUoS9pgaS9kv5B0gFJf5bavy3pD5L2pdvnyvZ5WNIRSYcl3VvWfpek/emxRyRpbt4W0D0W+gfn7CXMzJpNNVfZvAR8OiLekzQP+KWk59Jj34+IPy/fWFIR2Ar0ATcC/1vSrRExAjwGbAP+HngW2Aw8x1y4fhUsWOrQNzMrM+WRfpS8l+7OS7eYZJctwFMRcSkijgJHgI2SVgFLIuKliAjgSeC+WVU/GQkKfe7eMTMrU1WfvqR2SfuAU8ALEfFyeuhrkl6V9CNJy1NbD3CsbPfB1NaT1se3V3q9bZIGJA0MDQ1V/27GK/TCyYMQk31HmZnlR1WhHxEjEbEBWE3pqP0OSl01twAbgBPAd9PmlfrpY5L2Sq+3MyL6I6K/q+sjE79Ur9ALl87B+eMzfw4zsxYyrdE7EfEu8LfA5og4mb4MRoHHgY1ps0FgTdluq4HjqX11hfa5091XWrpf38wMqG70TpekZWm9E/gM8Hrqox/zBeC1tL4H2CppvqR1wHpgb0ScAC5I2pRG7dwPPFO7t1JBobe0dOibmQHVjd5ZBeyS1E7pS2J3RPxc0l9K2kCpi+Yt4KsAEXFA0m7gIDAMbE8jdwAeBJ4AOimN2pmbkTtjOpfD9TeW+vXNzGzq0I+IV4E7K7R/eZJ9dgA7KrQPAHdMs8bZKfT6SN/MLGndX+SO6S7C0GEYGc66EjOzzLV+6BeKMHIJ3jmadSVmZpnLR+gDnDyQbR1mZg2g9UO/6zZQm3+Za2ZGHkJ/XiesuNknc83MyEPog0fwmJklOQn9Ipx9E658kHUlZmaZyk/ox2hp6KaZWY7lJ/TBJ3PNLPfyEforbob2+XDKwzbNLN/yEfrtHdB1q4/0zSz38hH6UJpFyxdeM7Ocy1Ho98KF4/DBO1lXYmaWmfyE/ocTqriLx8zyKz+h7wlVzMxyFPpLemD+Uh/pm1mu5Sf0pdLRvk/mmlmO5Sf04eo1eCKyrsTMLBPVTIy+QNJeSf8g6YCkP0vtKyS9IOmNtFxets/Dko5IOizp3rL2uyTtT489kiZIr5/uPvjju3DhRF1f1sysUVRzpH8J+HREfBLYAGyWtAl4CHgxItYDL6b7SCoCW4E+YDPwaJpUHeAxYBuwPt021+6tVMEnc80s56YM/Sh5L92dl24BbAF2pfZdwH1pfQvwVERcioijwBFgo6RVwJKIeCkiAniybJ/6+HAWLYe+meVTVX36ktol7QNOAS9ExMtAd0ScAEjLQtq8BzhWtvtgautJ6+PbK73eNkkDkgaGhoam8XamsHAFLP6YR/CYWW5VFfoRMRIRG4DVlI7a75hk80r99DFJe6XX2xkR/RHR39XVVU2J1esu+sJrZpZb0xq9ExHvAn9LqS/+ZOqyIS1Ppc0GgTVlu60Gjqf21RXa66tQLF1Xf3Sk7i9tZpa1akbvdElaltY7gc8ArwN7gAfSZg8Az6T1PcBWSfMlraN0wnZv6gK6IGlTGrVzf9k+9VMowvAf4ezRur+0mVnWOqrYZhWwK43AaQN2R8TPJb0E7Jb0FeBt4IsAEXFA0m7gIDAMbI+IscPqB4EngE7guXSrr/IRPCs/UfeXNzPL0pShHxGvAndWaD8D3DPBPjuAHRXaB4DJzgfMva7bAZVCv/j5TEsxM6u3fP0iF+C6hbBincfqm1ku5S/0odSv72GbZpZD+Q39M7+DK3/MuhIzs7rKaej3QozA6d9mXYmZWV3lM/Q/nEXL/fpmli/5DP0VN0P7dQ59M8udfIZ++zxYeZsvvGZmuZPP0Ic0oYpH8JhZvuQ39LuLcH4QPng360rMzOomv6E/dm39odezrcPMrI4c+id9mWUzy4/8hv7S1XDd9e7XN7NcyW/oSz6Za2a5k9/Qh6uzaEXFCbzMzFpOvkO/UIQP3oH3TmZdiZlZXTj0wSdzzSw3HPrgfn0zy418h/6iG2Bxt6/BY2a5Uc3E6Gsk/ULSIUkHJH09tX9b0h8k7Uu3z5Xt87CkI5IOS7q3rP0uSfvTY4+kCdKzVeh16JtZblRzpD8MfDMieoFNwHZJqV+E70fEhnR7FiA9thXoAzYDj6ZJ1QEeA7YB69Ntc+3eygwV+uDU6zA6MvW2ZmZNbsrQj4gTEfHrtH4BOAT0TLLLFuCpiLgUEUeBI8BGSauAJRHxUkQE8CRw32zfwKwVemH4A3jnrawrMTObc9Pq05e0FrgTeDk1fU3Sq5J+JGl5ausBjpXtNpjaetL6+PZsfXgy1108Ztb6qg59SYuBp4FvRMR5Sl01twAbgBPAd8c2rbB7TNJe6bW2SRqQNDA0NFRtiTNTuL209AgeM8uBqkJf0jxKgf/jiPgZQEScjIiRiBgFHgc2ps0HgTVlu68Gjqf21RXaPyIidkZEf0T0d3V1Tef9TN91i2D5Wh/pm1kuVDN6R8APgUMR8b2y9lVlm30BeC2t7wG2SpovaR2lE7Z7I+IEcEHSpvSc9wPP1Oh9zE6hz7NomVkudFSxzd3Al4H9kvaltm8BX5K0gVIXzVvAVwEi4oCk3cBBSiN/tkfE2NCYB4EngE7guXTLXqEXfvs8DF+CjvlZV2NmNmemDP2I+CWV++OfnWSfHcCOCu0DwB3TKbAuuosQI3D6t/Cxf5R1NWZmcybfv8gd48sxmFlOOPQBbvgEtM3zhdfMrOU59AHa58HKW32kb2Ytz6E/prvoYZtm1vIc+mMKvXDuGPzxfNaVmJnNGYf+GJ/MNbMccOiP8TV4zCwHHPpjlq6B6xb7SN/MWppDf0xbmydUMbOW59AvV+gtjdWPihf/NDNreg79coU++OAsvHcq60rMzOaEQ79cobe0dBePmbUoh3657r7S0qFvZi3KoV9u0UpY1OXQN7OW5dAfr1D0hCpm1rIc+uMVijD0OoyOZl2JmVnNOfTHK/TClffh3beyrsTMrOYc+uN9eDLXv8w1s9bj0B+v67bS0idzzawFTRn6ktZI+oWkQ5IOSPp6al8h6QVJb6Tl8rJ9HpZ0RNJhSfeWtd8laX967BFJlebezdb862HZx30y18xaUjVH+sPANyOiF9gEbJdUBB4CXoyI9cCL6T7psa1AH7AZeFRSe3qux4BtwPp021zD91I7haK7d8ysJU0Z+hFxIiJ+ndYvAIeAHmALsCtttgu4L61vAZ6KiEsRcRQ4AmyUtApYEhEvRUQAT5bt01i6i3DmDRi+nHUlZmY1Na0+fUlrgTuBl4HuiDgBpS8GoJA26wGOle02mNp60vr49kqvs03SgKSBoaGh6ZRYG4UijA6Xgt/MrIVUHfqSFgNPA9+IiMnmFKzUTx+TtH+0MWJnRPRHRH9XV1e1JdbO2IQq7tc3sxZTVehLmkcp8H8cET9LzSdTlw1pOXZpykFgTdnuq4HjqX11hfbGc8MnoK3DI3jMrOVUM3pHwA+BQxHxvbKH9gAPpPUHgGfK2rdKmi9pHaUTtntTF9AFSZvSc95ftk9j6bgOVt7q0DezltNRxTZ3A18G9kval9q+BXwH2C3pK8DbwBcBIuKApN3AQUojf7ZHxEja70HgCaATeC7dGlOhFwZ/lXUVZmY1NWXoR8QvqdwfD3DPBPvsAHZUaB8A7phOgZkp9MJrT8OlC6Wx+2ZmLcC/yJ1IYexyDK9nW4eZWQ059CfiWbTMrAU59Cey7OMwb5FD38xaikN/Im1tULjdoW9mLcWhPxnPomVmLcahP5lCEd4/De9lcCkIM7M54NCfTHe6HMOpA9nWYWZWIw79yYxdg8eXWTazFuHQn8ziAixcCSd9pG9mrcGhP5VCr4/0zaxlOPSnMjaL1uho1pWYmc2aQ38q3UW4chHOvZ11JWZms+bQn4pP5ppZC3HoT6Xr9tLSJ3PNrAU49KeyYAksvclH+mbWEhz61egu+ho8ZtYSHPrVKPTC6d/C8OWsKzEzmxWHfjUKfTA6DGeOZF2JmdmsVDMx+o8knZL0WlnbtyX9QdK+dPtc2WMPSzoi6bCke8va75K0Pz32SJocvTl4QhUzaxHVHOk/AWyu0P79iNiQbs8CSCoCW4G+tM+jktrT9o8B24D16VbpORvTyluhrcOhb2ZNb8rQj4i/A85W+XxbgKci4lJEHAWOABslrQKWRMRLERHAk8B9M6y5/jqugxs+4RE8Ztb0ZtOn/zVJr6bun+WprQc4VrbNYGrrSevj2yuStE3SgKSBoaEGuZZ9oddj9c2s6c009B8DbgE2ACeA76b2Sv30MUl7RRGxMyL6I6K/q6trhiXWWKEP3v09XHov60rMzGZsRqEfEScjYiQiRoHHgY3poUFgTdmmq4HjqX11hfbmMXYyd+hwtnWYmc3CjEI/9dGP+QIwNrJnD7BV0nxJ6yidsN0bESeAC5I2pVE79wPPzKLu+vMsWmbWAjqm2kDST4A/AVZKGgT+C/AnkjZQ6qJ5C/gqQEQckLQbOAgMA9sjYiQ91YOURgJ1As+lW/NYthbmLfTJXDNralOGfkR8qULzDyfZfgewo0L7AHDHtKprJG1tpYuv+WSumTUx/yJ3OsYmVDEza1IO/enoLsLFU3DxdNaVmJnNiEN/Onw5BjNrcg796Sj0lZYnHfpm1pwc+tOxuACdK3ykb2ZNy6E/HVI6mevQN7Pm5NCfru40gicmvIqEmVnDcuhPV6EXLr8H545Nva2ZWYNx6E+XT+aaWRNz6E9X4fbS0v36ZtaEHPrTtWApLF3j0DezpuTQn4lCry/HYGZNyaE/E4Vi6br6I1eyrsTMbFoc+jNRKMLoFTjzu6wrMTObFof+THhCFTNrUg79mbhhPajd/fpm1nQc+jMxbwHccIvH6ptZ03Hoz5SvwWNmTWjK0Jf0I0mnJL1W1rZC0guS3kjL5WWPPSzpiKTDku4ta79L0v702CNpgvTmVSjCO2/B5YtZV2JmVrVqjvSfADaPa3sIeDEi1gMvpvtIKgJbgb60z6OS2tM+jwHbgPXpNv45m0t3EQgYej3rSszMqjZl6EfE3wFnxzVvAXal9V3AfWXtT0XEpYg4ChwBNkpaBSyJiJciIoAny/ZpToWxETw+mWtmzWOmffrdEXECIC0Lqb0HKL/85GBq60nr49srkrRN0oCkgaGhoRmWOMeWr4WOTp/MNbOmUusTuZX66WOS9ooiYmdE9EdEf1dXV82Kq6m2dui6zSdzzaypzDT0T6YuG9LyVGofBNaUbbcaOJ7aV1dob27dfQ59M2sqMw39PcADaf0B4Jmy9q2S5ktaR+mE7d7UBXRB0qY0auf+sn2aV6EX3jsJF89kXYmZWVWqGbL5E+Al4DZJg5K+AnwH+KykN4DPpvtExAFgN3AQeB7YHhEj6akeBH5A6eTu74Dnavxe6u/Dk7k+2jez5tAx1QYR8aUJHrpngu13ADsqtA8Ad0yrukZXPoJn3T/LthYzsyr4F7mzcf3HYMEyX3jNzJqGQ382pHQy12P1zaw5OPRna2wWrZhwBKqZWcNw6M9WoQiXzsO5wam3NTPLmEN/tnw5BjNrIg792Sr0lpY+mWtmTcChP1udy2BJj4/0zawpOPRroVD0hdfMrCk49Guh0AunD8PIcNaVmJlNyqFfC919MHIZzv4u60rMzCbl0K+FD0/muovHzBqbQ78WVt4KanO/vpk1PId+LczrhBW3+EjfzBqeQ79WCr0OfTNreA79Wunug7NH4fL7WVdiZjYhh36tFHqBKA3dNDNrUA79Win0lZY+mWtmDcyhXysr1kHHAvfrm1lDm1XoS3pL0n5J+yQNpLYVkl6Q9EZaLi/b/mFJRyQdlnTvbItvKG3t0HWbQ9/MGlotjvT/RURsiIj+dP8h4MWIWA+8mO4jqQhsBfqAzcCjktpr8PqNo1D0hdfMrKHNRffOFmBXWt8F3FfW/lREXIqIo8ARYOMcvH52Cr1w4QS8fzbrSszMKppt6AfwN5JekbQttXVHxAmAtCyk9h7gWNm+g6mtdYydzPXRvpk1qI5Z7n93RByXVABekPT6JNuqQlvFiWXTF8g2gJtuummWJdZR+TV41t6dbS1mZhXM6kg/Io6n5Sngryl115yUtAogLU+lzQeBNWW7rwaOT/C8OyOiPyL6u7q6ZlNifS25ERYs9clcM2tYMw59SYskXT+2DvxL4DVgD/BA2uwB4Jm0vgfYKmm+pHXAemDvTF+/IUmeUMXMGtpsune6gb+WNPY8/zMinpf0K2C3pK8AbwNfBIiIA5J2AweBYWB7RIzMqvpGVCjC/p9CROlLwMysgcw49CPiTeCTFdrPAPdMsM8OYMdMX7MpFHrh0jk4fxyWttZ5ajNrfv5Fbq11j43gcRePmTUeh36teRYtM2tgDv1a61wO19/ok7lm1pAc+nPBE6qYWYNy6M+FQi8MHYaR4awrMTO7hkN/LnT3wcgleOdo1pWYmV3DoT8Xxk7mnjyQbR1mZuM49OdC1+2AfOE1M2s4Dv25MK8TVtwMp3ykb2aNxaE/V7o9oYqZNR6H/lwpFOHsm3Dlg6wrMTP7kEN/rhSKEKOloZtmZg3CoT9XCsXS0l08ZtZAHPpzZcXN0D7fJ3PNrKE49OdKewd03eojfTNrKA79ueRZtMyswTj051KhCBeOwwfvZF2JmRng0J9bPplrZg1mNnPk2lS6U+g//xAU+mDRDbBwJSxaWVouvOFq2/zrPaeumc25uoe+pM3AXwDtwA8i4jv1rqFulvTAp+6H4/vg6P+Fi6dLV9+spP26j34RLEr3F95w9YtirK1zObS11/XtmFnzq2voS2oH/jvwWWAQ+JWkPRHRmmc7Jfj8f7t6PwIuX4T3T8PFM/D+mbR+urR8/0xqPw3v/B7eP1uaZL3ic7eVgn/CL4qV17Z1roC2jvS/CZWW/p+FWe7U+0h/I3AkIt4EkPQUsAWoeej/28f/nrdOX/xIu6YZdBNtXqldVN544pecB6wCVlXeswM62q+wNC6wnPMsjfMsjXMsi/Msi3MsvXyBpZfOsezseZZxjCVxnqVxgXZGp3xf5UYRkSqItB7pHY2tB21pObatPrwPIlT+2GTPk750xomKbePNdD+Iin8I1f9dqPQ6E287PdN57rnTCDXYeB/7073MX7Cwps9Z79DvAY6V3R8E/vH4jSRtA7YB3HTTTTN6oU/dtJyeZZ3XtE30jzEmeCAm2qNC88TPPXUETLVFRBcAV4DT6TbRcyhG6Ry9wOKRcywefre0HHmXRSPnUIxeG71xNcYB2hgt3Q/K2q+NeGKCWI9AjF7z2PjnElHxzapyTE+5TeWYqrRdpT+w6qN5enE4vciv/N7rrRFqsEpWqfZjbeod+pX+/Xzkb1xE7AR2AvT398/ob+R/vve2mexmZtbS6j1kcxBYU3Z/NXC8zjWYmeVWvUP/V8B6SeskXQdsBfbUuQYzs9yqa/dORAxL+hrwvygN2fxRRPiKZGZmdVL3cfoR8SzwbL1f18zMfBkGM7NcceibmeWIQ9/MLEcc+mZmOaJqfjGaJUlDwO9nuPtKKv+ANa/8eVzlz+Ja/jyuapXP4uMx9nP+Mg0f+rMhaSAi+rOuo1H487jKn8W1/Hlc1eqfhbt3zMxyxKFvZpYjrR76O7MuoMH487jKn8W1/Hlc1dKfRUv36ZuZ2bVa/UjfzMzKOPTNzHKkJUNf0mZJhyUdkfRQ1vVkSdIaSb+QdEjSAUlfz7qmrElql/QbST/PupasSVom6aeSXk9/R/5J1jVlSdJ/Sv9OXpP0E0kLsq6p1lou9MsmX/9XQBH4kqRitlVlahj4ZkT0ApuA7Tn/PAC+DhzKuogG8RfA8xFxO/BJcvy5SOoB/iPQHxF3ULr8+9Zsq6q9lgt9yiZfj4jLwNjk67kUESci4tdp/QKlf9Q92VaVHUmrgX8N/CDrWrImaQnwz4EfAkTE5Yh4N9OistcBdErqABbSgjP7tWLoV5p8PbchV07SWuBO4OWMS8nSfwX+FBjNuI5GcDMwBPyP1N31A0mLsi4qKxHxB+DPgbeBE8C5iPibbKuqvVYM/aomX88bSYuBp4FvRMT5rOvJgqR/A5yKiFeyrqVBdACfAh6LiDuBi0Buz4FJWk6pV2AdcCOwSNK/y7aq2mvF0Pfk6+NImkcp8H8cET/Lup4M3Q18XtJblLr9Pi3pr7ItKVODwGBEjP3P76eUvgTy6jPA0YgYiogrwM+Af5pxTTXXiqHvydfLSBKlPttDEfG9rOvJUkQ8HBGrI2Itpb8X/yciWu5IrloR8f+AY5JuS033AAczLClrbwObJC1M/27uoQVPbNd9jty55snXP+Ju4MvAfkn7Utu30lzFZv8B+HE6QHoT+PcZ15OZiHhZ0k+BX1Ma9fYbWvCSDL4Mg5lZjrRi946ZmU3AoW9mliMOfTOzHHHom5nliEPfzCxHHPpmZjni0Dczy5H/D4nitWl91LkcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history['avg_train_loss'])\n",
    "plt.plot(validation_history['avg_val_loss'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5176260fbc2cf1b78dfea4cc2edeb44537a6fdfe3203945a451ce281e8b97dc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('geopandas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
