
Training the network for 40 epochs, with a batch size of 16































































































































Training Epoch [11/40]:  56%|â–Œ| 61/109 [00:11<00:07,  6.78it/s, acc=0.79541665, dice=0.0063000503, iou=0.