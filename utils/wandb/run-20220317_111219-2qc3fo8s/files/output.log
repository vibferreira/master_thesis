
Training the network for 2 epochs, with a batch size of 2 and 1 iterations per epoch ðŸ¤—
  0%|          | 0/2 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s]
loss tensor(0.9995, grad_fn=<MeanBackward0>)


 20%|â–ˆâ–ˆ        | 2/10 [00:09<00:36,  4.54s/it, acc=53.1, iou=0.349, loss=0.998]
loss tensor(0.9976, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9963, grad_fn=<MeanBackward0>)


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:18<00:27,  4.57s/it, acc=114, iou=1.11, loss=0.996]
loss tensor(0.9962, grad_fn=<MeanBackward0>)

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:23<00:23,  4.65s/it, acc=157, iou=1.18, loss=0.999]
loss tensor(0.9995, grad_fn=<MeanBackward0>)

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:28<00:19,  4.80s/it, acc=192, iou=1.93, loss=0.994]
loss tensor(0.9941, grad_fn=<MeanBackward0>)

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:32<00:14,  4.75s/it, acc=246, iou=2.02, loss=0.999]
loss tensor(0.9994, grad_fn=<MeanBackward0>)

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:37<00:09,  4.63s/it, acc=299, iou=2.17, loss=0.999]
loss tensor(0.9989, grad_fn=<MeanBackward0>)

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:41<00:04,  4.53s/it, acc=358, iou=2.4, loss=0.998]
loss tensor(0.9985, grad_fn=<MeanBackward0>)

[INFO] Training Loop
loss tensor(0.9928, grad_fn=<MeanBackward0>)
[INFO] Training Loop
avg tensor(0.9928, grad_fn=<MeanBackward0>)
avg 37.99283981323242
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:54<00:54, 54.27s/it]
  0%|          | 0/10 [00:00<?, ?it/s]
loss tensor(0.9989, grad_fn=<MeanBackward0>)


 20%|â–ˆâ–ˆ        | 2/10 [00:07<00:30,  3.86s/it, acc=123, iou=0.852, loss=0.995]
loss tensor(0.9948, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9934, grad_fn=<MeanBackward0>)

 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:11<00:26,  3.80s/it, acc=174, iou=1.55, loss=0.993]
loss tensor(0.9926, grad_fn=<MeanBackward0>)

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:15<00:23,  3.86s/it, acc=223, iou=2.34, loss=0.993]
loss tensor(0.9989, grad_fn=<MeanBackward0>)

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:19<00:19,  3.88s/it, acc=291, iou=2.49, loss=0.999]
loss tensor(0.9925, grad_fn=<MeanBackward0>)

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:23<00:15,  3.93s/it, acc=331, iou=3.1, loss=0.992]
loss tensor(0.9989, grad_fn=<MeanBackward0>)

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:27<00:11,  3.98s/it, acc=402, iou=3.24, loss=0.999]
loss tensor(0.9975, grad_fn=<MeanBackward0>)


 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:35<00:04,  4.13s/it, acc=550, iou=3.98, loss=0.997]
loss tensor(0.9969, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9926, grad_fn=<MeanBackward0>)
[INFO] Training Loop
avg tensor(0.9926, grad_fn=<MeanBackward0>)

avg 57.24021911621094
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:43<00:00, 51.61s/it]