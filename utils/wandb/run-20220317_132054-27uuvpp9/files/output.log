
Training the network for 2 epochs, with a batch size of 2 and 1 iterations per epoch ðŸ¤—
  0%|          | 0/2 [00:00<?, ?it/s]

 10%|â–ˆ         | 1/10 [00:04<00:43,  4.88s/it, acc=tensor(0.4510), iou=tensor(0.0002), loss=1]
loss tensor(0.9996, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9959, grad_fn=<MeanBackward0>)

 20%|â–ˆâ–ˆ        | 2/10 [00:09<00:36,  4.50s/it, acc=tensor(0.7306), iou=tensor(0.0015), loss=0.996]
loss tensor(0.9976, grad_fn=<MeanBackward0>)


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:19<00:29,  4.89s/it, acc=tensor(0.7226), iou=tensor(0.0007), loss=0.999]
loss tensor(0.9992, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9992, grad_fn=<MeanBackward0>)

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:23<00:23,  4.76s/it, acc=tensor(0.7208), iou=tensor(0.0008), loss=0.999]
loss tensor(0.9963, grad_fn=<MeanBackward0>)

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:28<00:19,  4.77s/it, acc=tensor(0.7462), iou=tensor(0.0029), loss=0.996]
loss tensor(0.9991, grad_fn=<MeanBackward0>)

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:33<00:13,  4.65s/it, acc=tensor(0.6189), iou=tensor(0.0006), loss=0.999]
loss tensor(0.9968, grad_fn=<MeanBackward0>)


 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:42<00:04,  4.60s/it, acc=tensor(0.6325), iou=tensor(0.0039), loss=0.994]
loss tensor(0.9936, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9932, grad_fn=<MeanBackward0>)
[INFO] Training Loop
avg tensor(0.9932, grad_fn=<MeanBackward0>)
avg tensor(0.6316)

ALL METRICS {'acc': tensor(0.5356), 'iou': tensor(0.0037), 'dice_coeff': tensor(0.0073), 'f1score': tensor(0.0073)}
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:55<00:55, 55.58s/it]
  0%|          | 0/10 [00:00<?, ?it/s]
loss tensor(0.9993, grad_fn=<MeanBackward0>)

 10%|â–ˆ         | 1/10 [00:03<00:35,  3.89s/it, acc=tensor(0.4877), iou=tensor(0.0004), loss=0.999]
loss tensor(0.9929, grad_fn=<MeanBackward0>)

 20%|â–ˆâ–ˆ        | 2/10 [00:07<00:30,  3.86s/it, acc=tensor(0.4138), iou=tensor(0.0037), loss=0.993]
loss tensor(0.9967, grad_fn=<MeanBackward0>)

 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:11<00:26,  3.81s/it, acc=tensor(0.4836), iou=tensor(0.0017), loss=0.997]
loss tensor(0.9989, grad_fn=<MeanBackward0>)

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:15<00:22,  3.79s/it, acc=tensor(0.6091), iou=tensor(0.0006), loss=0.999]
loss tensor(0.9988, grad_fn=<MeanBackward0>)

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:19<00:19,  3.81s/it, acc=tensor(0.6660), iou=tensor(0.0007), loss=0.999]
loss tensor(0.9942, grad_fn=<MeanBackward0>)


 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:26<00:11,  3.81s/it, acc=tensor(0.7471), iou=tensor(0.0009), loss=0.999]
loss tensor(0.9985, grad_fn=<MeanBackward0>)

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:30<00:07,  3.91s/it, acc=tensor(0.7313), iou=tensor(0.0030), loss=0.995]
loss tensor(0.9947, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9930, grad_fn=<MeanBackward0>)

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:35<00:04,  4.06s/it, acc=tensor(0.7872), iou=tensor(0.0039), loss=0.993]
loss tensor(0.9927, grad_fn=<MeanBackward0>)
[INFO] Training Loop
avg tensor(0.9927, grad_fn=<MeanBackward0>)
avg tensor(0.6373)

ALL METRICS {'acc': tensor(0.7524), 'iou': tensor(0.0038), 'dice_coeff': tensor(0.0077), 'f1score': tensor(0.0077)}
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:44<00:00, 52.20s/it]