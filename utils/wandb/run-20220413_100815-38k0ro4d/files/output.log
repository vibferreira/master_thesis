
Training the network for 150 epochs, with a batch size of 8

  0%|                                                                            | 0/427 [00:00<?, ?it/s]
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 149, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 397, in _communicate_network_status
    resp = self._communicate(req, local=True)
