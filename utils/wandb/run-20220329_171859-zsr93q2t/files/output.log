
Training the network for 2 epochs, with a batch size of 8







































Training Epoch [0/2]:  99%|â–‰| 298/300 [01:19<00:00,  4.93it/s, acc=0.9452076, dice=0.8777985, iou=0.78221

<class 'torch.Tensor'>
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 149, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 397, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 222, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/share/etud/e2008984/miniconda3/envs/torch_env/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 227, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
