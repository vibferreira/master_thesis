
Training the network for 2 epochs, with a batch size of 2 and 1 iterations per epoch ðŸ¤—
  0%|          | 0/2 [00:00<?, ?it/s]

 10%|â–ˆ         | 1/10 [00:06<01:00,  6.70s/it, acc=tensor(0.7237), iou=tensor(0.0009), loss=0.998]
loss tensor(0.9982, grad_fn=<MeanBackward0>)

 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:56,  7.01s/it, acc=tensor(0.6484), iou=tensor(0.0019), loss=0.996]
loss tensor(0.9964, grad_fn=<MeanBackward0>)

 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:50,  7.19s/it, acc=tensor(0.6864), iou=tensor(0.0006), loss=0.999]
loss tensor(0.9992, grad_fn=<MeanBackward0>)
[INFO] Training Loop
loss tensor(0.9990, grad_fn=<MeanBackward0>)

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:39,  6.61s/it, acc=tensor(0.6572), iou=tensor(0.0005), loss=0.999]
loss tensor(0.9973, grad_fn=<MeanBackward0>)

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:32,  6.57s/it, acc=tensor(0.7289), iou=tensor(0.0009), loss=0.997]
loss tensor(0.9953, grad_fn=<MeanBackward0>)

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:25,  6.37s/it, acc=tensor(0.7363), iou=tensor(0.0024), loss=0.995]
loss tensor(0.9944, grad_fn=<MeanBackward0>)

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:18,  6.09s/it, acc=tensor(0.5176), iou=tensor(0.0029), loss=0.994]
loss tensor(0.9965, grad_fn=<MeanBackward0>)

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:51<00:12,  6.06s/it, acc=tensor(0.5333), iou=tensor(0.0019), loss=0.997]
loss tensor(0.9960, grad_fn=<MeanBackward0>)

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:06,  6.24s/it, acc=tensor(0.6099), iou=tensor(0.0023), loss=0.996]
loss tensor(0.9925, grad_fn=<MeanBackward0>)
[INFO] Training Loop

(2, 512, 512)
(2, 512, 512)
(2, 512, 512)
(2, 512, 512)

  0%|          | 0/2 [01:14<?, ?it/s]