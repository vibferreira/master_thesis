
Training the network for 1 epochs, with a batch size of 8



















































Training Epoch [0/1]:  98%|â–‰| 214/218 [01:40<00:01,  2.05it/s, acc=0.8397101, dice=0.0030221448, iou=0.00











