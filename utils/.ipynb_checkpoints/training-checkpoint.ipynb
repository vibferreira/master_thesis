{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/etud/e2008984/miniconda3/envs/env_thesis/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import model\n",
    "import metrics\n",
    "import config\n",
    "import utis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from dataset import HistoricalImagesDataset\n",
    "import config\n",
    "import glob\n",
    "\n",
    "# Ignore excessive warnings\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# WandB – Import the wandb library\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMAGES_PATH = '../data/patches/images/1942'\n",
    "MASK_PATH = '../data/patches/masks/1942'\n",
    "BEST_MODEL = '../best_model'\n",
    "# PREDICTIONS_PATH = \n",
    "\n",
    "image_paths = glob.glob(IMAGES_PATH +'/*.tif')[:40]\n",
    "mask_paths = glob.glob(MASK_PATH +'/*.tif')[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Object \n",
    "print('Number of image patches:', len(image_paths),'\\nNumber of mask patches:', len(mask_paths))\n",
    "dataset = HistoricalImagesDataset(image_paths, mask_paths)\n",
    "data = next(iter(dataset))\n",
    "print('shape image', data[0].shape, 'shape mask', data[1].shape)       \n",
    "\n",
    "# Train, Test, Split -- DEVEOLP A SPLITTING STRATEGY BASED ON THE SPATIAL INFORMATION !!!!!!!!!\n",
    "print('Splitting data into TRAIN, VAL and TEST')\n",
    "train_size = int(0.5 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) #-- pytorch alternative to the train_test_split command line from Scikit-Learn\n",
    "\n",
    "train_size = int(0.5 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "test_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "print(\"Training set size: \", len(train_dataset))\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size = config.BATCH_SIZE)\n",
    "print(\"Validation set size: \", len(val_dataset))\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size = config.BATCH_SIZE)\n",
    "print(\"Testing set size: \", len(test_dataset))\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size = config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{config.DEVICE} is available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, lossFunc, epoch):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # Save total train loss\n",
    "    totalTrainLoss = 0\n",
    "    \n",
    "    # metrics\n",
    "    accuracy = 0\n",
    "    iou = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    # loop over the training set\n",
    "    loop = tqdm(dataloader, leave=False)\n",
    "    for x, y in loop:\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(config.DEVICE), y.float().to(config.DEVICE))\n",
    "        \n",
    "        # forward\n",
    "        # with torch.cuda.amp.autocast(): # setting float16 to speed up the traiing\n",
    "        pred = model(x)\n",
    "        loss = lossFunc(pred, y)\n",
    "        \n",
    "        optim.zero_grad()  # zero out any previously accumulated gradients\n",
    "        loss.backward() # obtain the gradients with respect to the loss\n",
    "        opt.step() # perform one step of gradient descendent\n",
    "        totalTrainLoss += loss  # add the loss to the total training loss so far \n",
    "        \n",
    "        # metrics      \n",
    "        all_metrics = metrics.metrics(pred, y)\n",
    "        accuracy += all_metrics['acc']\n",
    "        iou += all_metrics['iou']\n",
    "        f1score += all_metrics['f1score']\n",
    "        \n",
    "        # update tqdm\n",
    "        loop.set_description(f'Training Epoch [{epoch}/{config.NUM_EPOCHS}]')\n",
    "        loop.set_postfix(loss=loss.item(), acc = all_metrics['acc'], iou=all_metrics['iou'])\n",
    "        \n",
    "    # calculate the average training loss PER EPOCH\n",
    "    avgTrainLoss = totalTrainLoss / len(dataloader)\n",
    "    avgAccLoss = accuracy / len(dataloader)\n",
    "    avgIOU = iou / len(dataloader)\n",
    "    avgF1score = f1score / len(dataloader)\n",
    "    \n",
    "    ## update training history\n",
    "    training_history[\"avg_train_loss\"].append(avgTrainLoss.cpu().detach().numpy()) # save the avg loss\n",
    "    training_history[\"train_accuracy\"].append(avgAccLoss) # save the acc \n",
    "    training_history[\"IoU\"].append(avgIOU) # save the iou\n",
    "    training_history[\"f1score\"].append(avgF1score) # save the f1score\n",
    "    \n",
    "    # WANDB\n",
    "    wandb.log({\n",
    "    # \"Examples\": example_images,\n",
    "    \"Train Loss\": avgTrainLoss,\n",
    "    \"Train Accuracy\": avgAccLoss,\n",
    "    \"IoU_train\":avgIOU})\n",
    "    \n",
    "    return training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader, lossFunc, epoch):\n",
    "    # Save total train loss\n",
    "    totalValLoss = 0\n",
    "    \n",
    "    # metrics\n",
    "    accuracy_val = 0\n",
    "    iou_val = 0\n",
    "    f1score_val = 0\n",
    "    \n",
    "    iter_ = 0\n",
    "    # switch off autograd\n",
    "    with torch.no_grad():\n",
    "    # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        loop = tqdm(dataloader, leave=False)\n",
    "        for (x_val, y_val) in loop:\n",
    "            # send the input to the device\n",
    "            (x_val, y_val) = (x_val.to(config.DEVICE), y_val.to(config.DEVICE))\n",
    "            \n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred_val = model(x_val)\n",
    "            loss = lossFunc(pred_val, y_val)\n",
    "            totalValLoss += loss\n",
    "            \n",
    "            # metrics      \n",
    "            all_metrics = metrics.metrics(pred_val, y_val)\n",
    "            accuracy_val += all_metrics['acc']\n",
    "            iou_val += all_metrics['iou']\n",
    "            f1score_val += all_metrics['f1score']\n",
    "            \n",
    "            # Plotting Val \n",
    "            iter_  % 5 = 0:\n",
    "                utis.plot_comparison(pred_val, y_val)\n",
    "            iter_ += 1 \n",
    "            print(iter_)\n",
    "            \n",
    "            # update tqdm\n",
    "            loop.set_description(f'Validation Epoch [{epoch}/{config.NUM_EPOCHS}]')\n",
    "            loop.set_postfix(loss_val=loss.item(), acc_val = all_metrics['acc'], iou_val=all_metrics['iou'])\n",
    "\n",
    "                        \n",
    "    # calculate the average VALIDATION loss PER EPOCH\n",
    "    avgValLoss = totalValLoss / len(dataloader)\n",
    "    avgAccLoss = accuracy_val / len(dataloader)\n",
    "    avgIOU = iou_val / len(dataloader)\n",
    "    avgF1score = f1score_val / len(dataloader)\n",
    "\n",
    "    ## update VALIDATION history\n",
    "    validation_history[\"avg_val_loss\"].append(avgValLoss.cpu().detach().numpy()) # save the avg loss\n",
    "    validation_history[\"val_accuracy\"].append(avgAccLoss) # save the acc\n",
    "    validation_history[\"IoU_val\"].append(avgIOU) # save the iou\n",
    "    validation_history[\"f1score_val\"].append(avgF1score) # save the iou\n",
    "    \n",
    "    # WANDB\n",
    "    wandb.log({\n",
    "    # \"Examples\": example_images,\n",
    "    \"Val Accuracy\": avgAccLoss,\n",
    "    \"Val Loss\": avgValLoss,\n",
    "    \"IoU_val\": avgIOU})\n",
    "    \n",
    "    return validation_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB – Initialize a new run\n",
    "wandb.init(entity=\"vibferreira\", project=\"master_thesis\")\n",
    "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release\n",
    "\n",
    "# Initialize our model\n",
    "unet = model.unet_model.to(config.DEVICE)\n",
    "\n",
    "# initialize loss function and optimizer\n",
    "lossFunc = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "opt = optim.Adam(unet.parameters(), lr=config.LR)\n",
    "\n",
    "# initialize a dictionary to store TRAINING history (keep track on training)\n",
    "training_history = {\"avg_train_loss\": [], \"train_accuracy\": [], \"IoU\":[],\"f1score\":[]}\n",
    "\n",
    "# # initialize a dictionary to store VALIDATION history (keep track on VALIDATION)\n",
    "validation_history = {\"avg_val_loss\": [], \"val_accuracy\": [], \"IoU_val\":[], \"f1score_val\":[]}\n",
    "\n",
    "# Using log=\"all\" log histograms of parameter values in addition to gradients\n",
    "wandb.watch(unet, log=\"all\")\n",
    "\n",
    "# initialize best accuracy\n",
    "best_accuracy = 0.0\n",
    "print(f'''Training the network for {config.NUM_EPOCHS} epochs, with a batch size of {config.BATCH_SIZE}''') # try with logger\n",
    "\n",
    "# loop = tqdm(range(config.NUM_EPOCHS))\n",
    "for e in range(config.NUM_EPOCHS):\n",
    "    trained = train(unet, train_dataloader, opt, lossFunc, epoch=e)\n",
    "    validated = validation(unet, val_dataloader, lossFunc, epoch=e)\n",
    "    \n",
    "    # Save best model\n",
    "    if validated['val_accuracy'][-1] > best_accuracy : # maybe add a minimum number of epochs as conditions\n",
    "        utis.save_best_model(unet, BEST_MODEL, validated, e)\n",
    "        best_accuracy = validation_history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_as_imgs():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].plot(training_history['avg_train_loss'], label= 'train')\n",
    "ax[0].plot(validation_history['avg_val_loss'], label='val')\n",
    "ax[0].set_title('Loss')\n",
    "ax[1].plot(training_history['train_accuracy'], label= 'train')\n",
    "ax[1].plot(validation_history['val_accuracy'], label='val')\n",
    "ax[1].set_title('Validation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5176260fbc2cf1b78dfea4cc2edeb44537a6fdfe3203945a451ce281e8b97dc2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
